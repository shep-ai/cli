# Feature: agent-memory-layer

> Implement persistent memory layer for AI agents using local-first TypeScript stack (Transformers.js + LanceDB + Quadstore + LangChain.js)

## Status

- **Number:** 011
- **Created:** 2026-02-09
- **Branch:** feat/agent-memory-layer
- **Phase:** Research

## Problem Statement

Our agents currently lack persistent memory across sessions. They cannot learn from past interactions, remember user preferences, or build contextual understanding over time. This limits their effectiveness and forces users to repeat information.

We need a memory layer that:

- Persists agent interactions and learnings across sessions
- Enables contextual recall based on current conversation
- Supports graph-based relationships between memories
- Integrates with our existing agent architecture (LangGraph-based)

## Success Criteria

- [ ] Local-first stack integrated (Transformers.js, LanceDB, Quadstore, LangChain.js)
- [ ] Memory persistence working for agent interactions (file-based storage)
- [ ] Agents can retrieve relevant past context during conversations (hybrid retrieval)
- [ ] Zero API keys required (100% self-hosted embeddings)
- [ ] Hybrid memory scoping (global + feature-specific graphs)
- [ ] Clean Architecture compliance (memory as infrastructure layer)
- [ ] Unit and integration tests covering memory operations

## Affected Areas

| Area                        | Impact | Reasoning                                                              |
| --------------------------- | ------ | ---------------------------------------------------------------------- |
| infrastructure/services     | High   | New memory service implementing graph-based storage                    |
| application/ports           | Medium | New IMemoryService port interface for agent memory operations          |
| infrastructure/di/container | Medium | Register memory service in DI container                                |
| domain/generated            | Low    | May need new TypeSpec models for memory entities (Episode, Node, Edge) |
| infrastructure/agents       | High   | Integrate memory into agent execution loop (StateGraph nodes)          |

## Dependencies

None identified.

## Size Estimate

**Large** - Requires:

- Research on Graphiti API and best practices
- TypeSpec domain modeling for memory entities
- New infrastructure service with graph database integration
- Integration with existing LangGraph agent system
- Comprehensive testing strategy (unit + integration)
- Documentation for memory operations

Estimated 5-8 implementation tasks over multiple development sessions.

## Open Questions

**All resolved during research:**

- [x] **Memory Scope:** Hybrid approach - global (Quadstore named graph `shep:global`) + feature-specific (`shep:feature:{id}`)
- [x] **Storage:** File-based with LanceDB (vectors) + Quadstore (graph) + Transformers.js (models)
- [x] **Retrieval:** Hybrid retrieval via LangChain.js - semantic search (LanceDB) + graph traversal (SPARQL) + keyword search
- [x] **Performance:** Target <300ms end-to-end retrieval, <50ms vector search, <100ms graph queries
- [x] **Configuration:** Embedding model (Transformers.js vs Ollama), storage paths, retention policies, pruning strategies
- [x] **API Keys:** NO API keys required - 100% local embeddings via Transformers.js ONNX Runtime

---

_Generated by `/shep-kit:new-feature` â€” proceed with `/shep-kit:research`_
